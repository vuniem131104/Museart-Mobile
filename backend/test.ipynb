{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd678b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82ab0bf8204452d80aa7ad021babe1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24192/89309463.py:18: DeprecationWarning: invalid escape sequence '\\&'\n",
      "  decoded = raw_html.encode('utf-8').decode('unicode_escape')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve data for page 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1854"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from langchain_core.documents.base import Document\n",
    "total_pages = 1854 \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def call_api(page):\n",
    "    url = f\"https://api.artic.edu/api/v1/products?page={page}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']\n",
    "    else:\n",
    "        return None    \n",
    "    \n",
    "def html_to_text(raw_html):\n",
    "    if raw_html:\n",
    "        decoded = raw_html.encode('utf-8').decode('unicode_escape')\n",
    "        soup = BeautifulSoup(decoded, 'html.parser')\n",
    "        text = soup.get_text(separator=' ')\n",
    "        clean_text = ' '.join(text.split())\n",
    "        return clean_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def generate_information(item):\n",
    "    product_title = item.get('title', 'Untitled')\n",
    "    raw_description = item.get('description', '')\n",
    "    description = html_to_text(raw_description)\n",
    "\n",
    "    decoded_price_html = html.unescape(item.get('price_display', ''))\n",
    "    match = re.search(r'\\$(\\d+(?:\\.\\d{1,2})?)', decoded_price_html)\n",
    "    if match:\n",
    "        price = float(match.group(1))\n",
    "    else:\n",
    "        price = 20.0  \n",
    "\n",
    "    image_url = item.get('image_url', '')\n",
    "\n",
    "    summary = (\n",
    "        f\"{product_title} is a beautifully crafted poster derived from the artwork featured in the exhibition. \"\n",
    "        f\"It has the description as: {description}. \"\n",
    "        f\"The piece reflects the powerful legacy of Frida Kahlo and Mary Reynolds as showcased in the Art Institute of Chicago. \"\n",
    "        f\"Priced at ${price:.2f}, it makes a unique addition to any art loverâ€™s collection.\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'product_title': product_title,\n",
    "        'price': price,\n",
    "        'image': image_url,\n",
    "        'summary': summary\n",
    "    }\n",
    "documents = []\n",
    "from tqdm.auto import tqdm \n",
    "for page in tqdm(range(1, total_pages + 1)):\n",
    "    data = call_api(page)\n",
    "    if data:\n",
    "        for item in data:\n",
    "            information = generate_information(item)\n",
    "            document = Document(page_content=information['summary'], metadata={\n",
    "                'product_title': information['product_title'],\n",
    "                'price': information['price'],\n",
    "                'image': information['image'],\n",
    "            })\n",
    "            documents.append(document)  \n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for page {page}\")\n",
    "        break\n",
    "    \n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31ce9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains import create_retrieval_chain, create_history_aware_retriever\n",
    "from langchain_chroma import Chroma\n",
    "def create_vector_embeddings():\n",
    "    all_docs = documents\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "    \n",
    "    final_docs = text_splitter.split_documents(all_docs)\n",
    "    \n",
    "    embedding_model = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "    \n",
    "    print(\"Loaded Embedding Model\")\n",
    "    \n",
    "    embeddings = Chroma.from_documents(final_docs, \n",
    "                                       embedding_model, \n",
    "                                       collection_name=\"art_collection\",\n",
    "                                       persist_directory=\"./art_products\")\n",
    "    print(\"Loaded Chroma\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f8935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Embedding Model\n",
      "Loaded Chroma\n",
      "AI Response:  The Festive Tree Flat Decorative Candle is priced at $20.00, which is less than $40.00, and can be used for decoration. It's a handmade flat candle made in Lithuania with high-quality materials. It makes a unique addition to any art lover's collection.\n",
      "History:  [HumanMessage(content='Hey, i want some product having price less than 40.0 and they can be used for decoration purpose. Can you help me with that?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The Festive Tree Flat Decorative Candle is priced at $20.00, which is less than $40.00, and can be used for decoration. It's a handmade flat candle made in Lithuania with high-quality materials. It makes a unique addition to any art lover's collection.\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(groq_api_key=os.getenv(\"GROQ_API_KEY\"), model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the questions based on the provided context only.\n",
    "    Please provide the most accurate respone based on the question\n",
    "    <context>\n",
    "    {context}\n",
    "    <context>\n",
    "    Question:{input}\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "embeddings = create_vector_embeddings()\n",
    "\n",
    "retriever = embeddings.as_retriever()\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "contextualize_q_system_prompt=(\n",
    "            \"Given a chat history and the latest user question\"\n",
    "            \"which might reference context in the chat history, \"\n",
    "            \"formulate a standalone question which can be understood \"\n",
    "            \"without the chat history. Do NOT answer the question, \"\n",
    "            \"just reformulate it if needed and otherwise return it as is.\"\n",
    "        )\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)\n",
    "\n",
    "system_prompt = (\n",
    "                \"You are an assistant for question-answering tasks. \"\n",
    "                \"Use the following pieces of retrieved context to answer \"\n",
    "                \"the question. If you don't know the answer, say that you \"\n",
    "                \"don't know. Use three sentences maximum and keep the \"\n",
    "                \"answer concise.\"\n",
    "                \"\\n\\n\"\n",
    "                \"{context}\"\n",
    "            )\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "question_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_chain)\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "    \n",
    "conversational_rag_chain=RunnableWithMessageHistory(\n",
    "    rag_chain,get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\"\n",
    ")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     while True:\n",
    "input_text = \"Hey, i want some product having price less than 40.0 and they can be used for decoration purpose. Can you help me with that?\"\n",
    "\n",
    "session_history = get_session_history(\"default\")\n",
    "answer = conversational_rag_chain.invoke({\n",
    "    \"input\": input_text\n",
    "}, config={\n",
    "    \"configurable\": {\"session_id\": \"default\"}\n",
    "})\n",
    "print(\"AI Response: \", answer[\"answer\"])\n",
    "print(\"History: \", session_history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d431e37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:  I can describe the product to you, but I'm a text-based AI and do not have the capability to provide direct links to products.\n",
      "\n",
      "The Festive Tree Flat Decorative Candle is a handmade flat candle made in Lithuania using high-quality German materials. It is dripless, smokeless, and self-extinguishing, and comes with an easy-to-assemble steel base. The dimensions of the candle are 2.4 x 0.4 x 5.9 inches and it is priced at $20.00.\n",
      "\n",
      "To find the product, I suggest searching online for \"Festive Tree Flat Decorative Candle\" or checking an online marketplace or store that sells it, such as the Art Institute of Chicago's website or an art store.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Describe the product in detail and provide the link to the product. I want to know about its price as well.\"\n",
    "\n",
    "session_history = get_session_history(\"default\")\n",
    "answer = conversational_rag_chain.invoke({\n",
    "    \"input\": input_text\n",
    "}, config={\n",
    "    \"configurable\": {\"session_id\": \"default\"}\n",
    "})\n",
    "print(\"AI Response: \", answer[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
